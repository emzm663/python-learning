import pandas as pd
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
select = SelectFromModel(RandomForestClassifier(n_estimators=1000, random_state=1),threshold="median")
d1=pd.read_csv() 
data1=d1.dropna(axis=0, how='any')
SourceData1=data1.drop(["y1_is_purchase"], axis=1)
SourceData2=data1["y1_is_purchase"].copy()
s1= StandardScaler()
SourceData1_scaled= s1.fit_transform(SourceData1)
x_train=SourceData1_scaled
y_train=SourceData2
select.fit(x_train, y_train)
x_train_l1 = select.transform(x_train)
a=select.get_support()
print("x_train.shape: {}".format(x_train.shape))
print("c_train_l1.shape: {}".format(x_train_l1.shape))
print(a)


#特征分析
import pandas as pd
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import lightgbm as lgb
d1=pd.read_csv() 
SourceData1=d1.drop(["y1_is_purchase"], axis=1)
SourceData2=d1["y1_is_purchase"].copy()
s1= StandardScaler()
SourceData1_scaled= s1.fit_transform(SourceData1)
x_train=SourceData1_scaled
y_train=SourceData2
model=lgb.LGBMRegressor(num_leaves=10,
                           max_depth=5,
                           learning_rate=0.1,
                           n_estimators=50,
                           subsample=0.8,
                           feature_fraction=0.8,
                           reg_alpha=0.5,
                           reg_lambda=0.5,
                           random_state=1,
                           metric='auc',
                           min_gain_to_split=0.1,
                           )
model.fit(x_train,y_train)
x_train1=pd.DataFrame(x_train)
feature_importance=pd.DataFrame()
feature_importance['features']=x_train1.columns
feature_importance['feature_importances']=model.feature_importances_
feature_importance.plot(kind = 'barh', figsize = (10, 100))
from sklearn import metrics
from pandas import DataFrame
import lightgbm as lgb
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
import pandas as pd
from sklearn.metrics import roc_auc_score
import warnings
from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
import gc
import numpy as np


warnings.filterwarnings('ignore')



d1=pd.read_csv('/home/mw/input/pre8881/train.csv',usecols=[1, 5, 6, 7, 8, 9, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 47, 53, 54, 55, 56, 60, 61, 62, 63, 64])
d4=pd.read_csv('/home/mw/input/pre8881/train.csv')
d1['a']=d4['nprem_od']/d4['si_od']
d1['b']=d4['nprem_tp']/d4['si_tp']
d1['c']=d4['suiche_nonauto_nprem_20']/d4['suiche_nonauto_amount_20']
d1['d']=d4['suiche_nonauto_nprem_19']/d4['suiche_nonauto_amount_19']
d1['e']=d4['suiche_nonauto_nprem_18']/d4['suiche_nonauto_amount_18']
d1['f']=d4['nprem_bt']/d4['si_bt']
d1['g']=d4['nprem_vld']/d4['si_vld']
d1['h']=d4['nprem_vlp']/d4['si_vlp']
d1['i']=d4['suiche_nonauto_nprem_17']/d4['suiche_nonauto_amount_17']
d1['j']=d4['suiche_nonauto_nprem_16']/d4['suiche_nonauto_amount_16']
d1['birth_month'] = d4['birth_month'].apply(lambda x: int(x[:-1]) if type(x) != float else 0)
d1['use_type'] = d4['use_type'].apply(lambda x: 1 if x =='营业'  else 0)
d1['p1_gender'] = d4['p1_gender'].apply(lambda x: 1 if x =='女'  else 0)
d1['p2_marital_status'] = d4['p2_marital_status'].apply(lambda x: 1 if x =='未婚'  else 0)
d1['p2_client_grade'] = d4['p2_client_grade'].apply(lambda x: 1 if x =='车主俱乐部-钻石客户-2'or'车主俱乐部-黑钻客户-2'or'车主俱乐部-黄金客户-2'or'车主俱乐部-铂金客户-2'  else 0)
k=['w1_pc_wx_use_flag','p1_is_bank_eff','p2_is_enterprise_owner','p2_is_smeowner','p2_is_child_under_15_family','p2_is_adult_over_55_family','f2_posses_house_flag','f1_child_flag','change_owner']
i=0
print('开始循环1 ==============================')
while i <len(k):
    d1[k[i]] = d4[k[i]].apply(lambda x: 1 if x =='是'  else 0)
    i=i+1
print('循环1结束 ==============================')
SourceData1=d1.drop(["y1_is_purchase"], axis=1)
SourceData2=d1["y1_is_purchase"].copy()
s1= StandardScaler()
zz1= s1.fit_transform(SourceData1)
x_train=zz1
y_train=SourceData2



d2=pd.read_csv('/home/mw/input/pretest_b6354/test_b.csv',usecols=[1, 5, 6, 7, 8, 9, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 47, 53, 54, 55, 56, 60, 61, 62, 63, 4])
d5=pd.read_csv('/home/mw/input/pretest_b6354/test_b.csv')
d2['a']=d5['nprem_od']/d5['si_od']
d2['b']=d5['nprem_tp']/d5['si_tp']
d2['c']=d5['suiche_nonauto_nprem_20']/d5['suiche_nonauto_amount_20']
d2['d']=d5['suiche_nonauto_nprem_19']/d5['suiche_nonauto_amount_19']
d2['e']=d5['suiche_nonauto_nprem_18']/d5['suiche_nonauto_amount_18']
d2['f']=d5['nprem_bt']/d5['si_bt']
d2['g']=d5['nprem_vld']/d5['si_vld']
d2['h']=d5['nprem_vlp']/d5['si_vlp']
d2['i']=d5['suiche_nonauto_nprem_17']/d5['suiche_nonauto_amount_17']
d2['j']=d5['suiche_nonauto_nprem_16']/d5['suiche_nonauto_amount_16']
d2['birth_month'] = d5['birth_month'].apply(lambda x: int(x[:-1]) if type(x) != float else 0)
d2['use_type'] = d5['use_type'].apply(lambda x: 1 if x =='营业'  else 0)
d2['p1_gender'] = d5['p1_gender'].apply(lambda x: 1 if x =='女'  else 0)
d2['p2_marital_status'] = d5['p2_marital_status'].apply(lambda x: 1 if x =='未婚'  else 0)
d2['p2_client_grade'] = d5['p2_client_grade'].apply(lambda x: 1 if x =='车主俱乐部-钻石客户-2'or'车主俱乐部-黑钻客户-2'or'车主俱乐部-黄金客户-2'or'车主俱乐部-铂金客户-2'  else 0)
ii=0
print('开始循环2 ==============================')
while ii <len(k):
    d2[k[ii]] = d5[k[ii]].apply(lambda x: 1 if x =='是'  else 0)
    ii=ii+1
print('循环2结束 ==============================')



SourceData3=d2.drop(['carid'],axis=1)
s2=StandardScaler()
zz2=s2.fit_transform(SourceData3)
x_test=zz2
gc.collect()



d3=pd.read_csv('/home/mw/input/pre8881/train.csv',nrows=80110) 
y_test=d3["y1_is_purchase"].copy()
y_pre=np.zeros(y_test.shape[0])
yy=np.zeros(y_train.shape[0])
print(x_train.shape)
print(x_test.shape)
print(y_pre.shape)
print(yy.shape)
print('数据处理结束')
train_x,X, train_y,Y = train_test_split(x_train, y_train, test_size=0.2, random_state = 2021) 
skf = StratifiedKFold(n_splits=5, random_state=2021, shuffle=True)
for index, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):#将数据五折分割
        train_x,X, train_y,Y= x_train[train_index],x_train[test_index], y_train[train_index], y_train[test_index]
        print('\n第{}折 ================================\n'.format(index+1))
        model=lgb.LGBMClassifier(num_leaves=512,
                           max_depth=16,
                           learning_rate=0.01,
                           n_estimators=80000,
                           subsample=0.8,
                           feature_fraction=0.2,
                           reg_alpha=0.1,
                           reg_lambda=0.1,
                           random_state=2021,
                           metric='auc',
                           min_gain_to_split=0.01,
                           )
        model.fit(train_x,train_y,
                eval_set=[(X, Y)],
                verbose=100,
                eval_metric='auc',
                early_stopping_rounds=240)
        gc.collect()
        y_pre+= model.predict(x_test)/5
print('运行结束')
k=y_pre
for s in range(len(k)):
    if float(k[s])>1:
        k[s]=1
    elif float(k[s])<0:
        k[s]=0
    else:
        k[s]=k[s]

list=d2["carid"].values.tolist()
n={"carid":list,"label":k}
dataframe = pd.DataFrame(n)
dataframe.to_csv("test.csv",index=False,sep=',')
